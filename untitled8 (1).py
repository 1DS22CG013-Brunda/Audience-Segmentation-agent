# -*- coding: utf-8 -*-
"""Untitled8.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1_AU-DVN3aIpQVuCUgEpbQEFFjaW7vv4w
"""

# Install all required libraries
!pip install pandas openpyxl scikit-learn matplotlib seaborn

!pip install -q -U langchain langchain-openai langchain_community


# Mount Google Drive to access your Excel file
from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
import numpy as np
import sqlite3
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.preprocessing import StandardScaler
from sqlalchemy import create_engine, inspect

file_path = '/content/drive/MyDrive/Colab Notebooks/AUDIENCE_PERSONAL_WITH_SYNTHETIC.xlsx'
df = pd.read_excel(file_path)

# Correct any data inconsistencies
df["payment_subscription"] = df["payment_subscription"].replace({
    'Credit Car Active': 'Credit Card Active',
    'Credit Car Inactive': 'Credit Card Inactive'
})

# Define features for clustering
features = [
    'age', 'login_days', 'support_tickets', 'last_transaction_amount',
    'total_transaction_count', 'total_transaction_amount',
    'no_of_referrals', 'referral_earning', 'average_transaction_amount'
]

encoded_features = [
    'Gender_e', 'loaction-e', 'Occupation_e',
    'purchase_frequency_category_e', 'Customervalue_e',
    'Lasttrans_cat_e', 'payment_method_e'
]

# --- Correct code starts here ---
columns_to_use = features + encoded_features
X = df[columns_to_use]

# Standardize and apply PCA
scaler = StandardScaler()
X_scaled = scaler.fit_transform(X)
pca = PCA(n_components=7)
X_pca = pca.fit_transform(X_scaled)

# Apply KMeans clustering
kmeans = KMeans(n_clusters=3, random_state=42)
labels = kmeans.fit_predict(X_pca)
df["Cluster"] = labels

# Assign human-readable cluster names
cluster_names = {
    0: "Value Seekers",
    1: "High Spenders",
    2: "Casual Users"
}
df["Cluster_name"] = df["Cluster"].map(cluster_names)

# Save to a SQLite database
conn = sqlite3.connect('user_data.db')
df.to_sql('users', conn, if_exists='replace', index=False)
conn.close()

# Verify the database creation
engine = create_engine("sqlite:///user_data.db")
inspector = inspect(engine)
print("Tables in DB:", inspector.get_table_names())

from sqlalchemy import create_engine, inspect

engine = create_engine("sqlite:///user_data.db")
insp = inspect(engine)
columns = [col["name"] for col in insp.get_columns("users")]
print(columns)

conn = sqlite3.connect("user_data.db")

df["last_transaction_date"] = pd.to_datetime(
    df["last_transaction_date"], errors="coerce"
).dt.strftime("%Y-%m-%d")

df.to_sql("users", conn, if_exists="replace", index=False)

conn.close()

conn = sqlite3.connect("user_data.db")
query = """
SELECT customerid, name, email_id, phone_number, last_transaction_category
FROM users
WHERE LOWER(last_transaction_category) IN ('skincare', 'haircare')
ORDER BY total_transaction_amount DESC
LIMIT 10;
"""
pd.read_sql(query, conn)

conn = sqlite3.connect("user_data.db") # Read first 5 rows from the 'users' table
df = pd.read_sql_query("SELECT * FROM users LIMIT 5;", conn) # Display the result
print(df) # Close the connection
conn.close()

conn = sqlite3.connect("user_data.db")
cur = conn.cursor()

cur.execute("""
CREATE TABLE IF NOT EXISTS category_lexicon (
  canonical TEXT NOT NULL,
  alias TEXT NOT NULL
);
""")

rows = [
    # Skincare
    ('skincare', 'skin care'),
    ('skincare', 'serum'),
    ('skincare', 'face cream'),
    ('skincare', 'moisturizer'),
    ('skincare', 'cleanser'),
    ('skincare', 'lotion'),
    ('skincare', 'toner'),
    ('skincare', 'sunscreen'),

    # Makeup
    ('makeup', 'cosmetics'),
    ('makeup', 'beauty'),
    ('makeup', 'lipstick'),
    ('makeup', 'foundation'),
    ('makeup', 'blush'),
    ('makeup', 'eyeliner'),
    ('makeup', 'mascara'),

    # Haircare
    ('haircare', 'shampoo'),
    ('haircare', 'conditioner'),
    ('haircare', 'hair oil'),
    ('haircare', 'hair serum'),
    ('haircare', 'styling gel'),
    ('haircare', 'hair color'),

    # Personal Care
    ('personal care', 'soap'),
    ('personal care', 'body wash'),
    ('personal care', 'toothpaste'),
    ('personal care', 'deodorant'),
    ('personal care', 'sanitizer'),
    ('personal care', 'hand wash'),

]

# Reset and insert
cur.execute("DELETE FROM category_lexicon;")
cur.executemany("INSERT INTO category_lexicon (canonical, alias) VALUES (?, ?)", rows)
conn.commit()
conn.close()

import os
!pip install pyngrok fastapi uvicorn
from langchain_openai import AzureChatOpenAI, ChatOpenAI
from langchain.agents import create_sql_agent
from langchain.agents.agent_toolkits import SQLDatabaseToolkit
from langchain.sql_database import SQLDatabase
from langchain_core.prompts import PromptTemplate
from flask import Flask, request, jsonify
from pyngrok import ngrok

os.environ["AZURE_OPENAI_ENDPOINT"] = "https://agenticaiopenai.openai.azure.com"
os.environ["AZURE_OPENAI_API_KEY"] = "****************w"
os.environ["OPENAI_API_VERSION"] = "2025-********"

llm = AzureChatOpenAI(
    openai_api_version=os.environ["OPENAI_API_VERSION"],
    azure_deployment="gpt-4o-mini",
    temperature=0
 )

from datetime import datetime
import numpy as np
from sqlalchemy import text
from langchain_core.tools import Tool
from langchain_community.utilities import SQLDatabase
from langchain_community.agent_toolkits import SQLDatabaseToolkit
from langchain.agents import initialize_agent
from langchain_core.prompts import PromptTemplate

# --------------------------------------------------------------------------------
# Step 1: DB Setup
# --------------------------------------------------------------------------------
db = SQLDatabase.from_uri("sqlite:///user_data.db")

# Custom safe SQL executor to strip markdown fences
def safe_sql_query(query: str):
    query = query.strip()
    if query.startswith("```"):
        query = query.replace("```sql", "").replace("```", "").strip()
    return db.run(query)

# --------------------------------------------------------------------------------
# Step 2: Helper Functions
# --------------------------------------------------------------------------------
def _simulate_single_churn_probability(row, colnames):
    """Convert row tuple → dict and simulate churn."""
    row_dict = dict(zip(colnames, row))

    # Parse dates
    days_since_txn, days_since_login = None, None
    if row_dict.get("last_transaction_date"):
        try:
            last_txn = datetime.strptime(str(row_dict["last_transaction_date"]).split(" ")[0], "%Y-%m-%d")
            days_since_txn = (datetime.now() - last_txn).days
        except:
            pass
    if row_dict.get("last_login_date"):
        try:
            last_login = datetime.strptime(str(row_dict["last_login_date"]).split(" ")[0], "%Y-%m-%d")
            days_since_login = (datetime.now() - last_login).days
        except:
            pass

    churn_risk = False
    if (days_since_txn and days_since_txn > 120) or (row_dict.get("support_tickets", 0) > 5):
        churn_risk = True

    return {
        "customerid": row_dict.get("customerid"),
        "name": row_dict.get("name"),
        "email": row_dict.get("email_id"),
        "phone": row_dict.get("phone_number"),
        "days_since_last_txn": days_since_txn,
        "days_since_last_login": days_since_login,
        "support_tickets": row_dict.get("support_tickets"),
        "churn_risk": churn_risk
    }

def churn_predictor_tool(*args, **kwargs):
    """Churn predictor tool with summary + explanation."""
    try:
        engine = db._engine
        with engine.connect() as conn:
            result = conn.execute(text("SELECT * FROM users"))
            rows = result.fetchall()
            colnames = result.keys()

        results = [_simulate_single_churn_probability(row, colnames) for row in rows]
        at_risk = [r for r in results if r.get("churn_risk")]

        if not at_risk:
            return "No matching users found based on the criteria."

        # Format list
        output_str = ""
        for i, c in enumerate(at_risk):
            output_str += (
                f"{i+1}) {c['name']} — CustomerID: {c['customerid']}, "
                f"Email: {c['email']}, Phone: {c['phone']}, "
                f"Churn Risk: {c['churn_risk']}\n"
            )

        # Summary + Explanation
        summary = f"\nSummary: Found {len(at_risk)} customers likely to churn. Suggest proactive retention with loyalty discounts."
        explanation = "\nExplanation: Churn risk calculated using rules (last_transaction_date > 120 days OR support_tickets > 5)."
        return output_str + summary + explanation

    except Exception as e:
        return f"Error in churn_predictor_tool: {e}"

# --------------------------------------------------------------------------------
# Step 3: Other Tools
# --------------------------------------------------------------------------------
def simulate_ltv_tool(customers: list) -> str:
    try:
        results = []
        for cust in customers:
            # Handle dict input
            if isinstance(cust, dict):
                cid = cust.get("customerid", "Unknown")
                current_ltv = cust.get("lifetime_value", 10000)
            else:
                # If it's just a string, use default values
                cid = str(cust)
                current_ltv = 10000  # fallback

            # Simple simulation: project +20% future LTV
            future_ltv = round(current_ltv * 1.2, 2)
            results.append(f"{cid}: Current LTV = {current_ltv}, Predicted Future LTV = {future_ltv}")

        summary = f"Predicted future LTV for {len(results)} customers."
        explanation = (
            "Future LTV projected using a simple growth factor (20%). "
            "In production, this can be replaced with ML models using features like "
            "transactions, tenure, referrals, etc."
        )

        return "\n".join(results) + "\n\nSummary: " + summary + "\nExplanation: " + explanation

    except Exception as e:
        return f"Error in simulate_ltv_tool: {str(e)}"


def simulate_product_affinity_tool(customers: list) -> str:
    try:
        from collections import defaultdict

        # Dictionary of product category → list of customers who bought it
        category_map = defaultdict(list)
        for cust in customers:
            cid = cust.get("customerid")
            name = cust.get("name")
            category = cust.get("last_transaction_category", "Unknown")

            if category:
                category_map[category].append(name)

        # Find simple affinities: if same customer appears in multiple categories
        affinities = defaultdict(list)
        for category, buyers in category_map.items():
            for other_category, other_buyers in category_map.items():
                if category != other_category:
                    common = set(buyers) & set(other_buyers)
                    if common:
                        affinities[category].append((other_category, list(common)))

        results = []
        for category, related in affinities.items():
            for (other_cat, customers_in_both) in related:
                results.append(
                    f"Affinity: {category} ↔ {other_cat} | Common buyers: {', '.join(customers_in_both)}"
                )

        summary = f"Identified {len(results)} product affinities."
        explanation = (
            "Affinity calculated by co-occurrence: customers appearing in multiple categories "
            "are flagged as having cross-category buying tendencies."
        )

        return "\n".join(results) + "\n\nSummary: " + summary + "\nExplanation: " + explanation

    except Exception as e:
        return f"Error in simulate_product_affinity_tool: {str(e)}"


# --------------------------------------------------------------------------------
# Step 4: Toolkit + Custom Tools
# --------------------------------------------------------------------------------
toolkit = SQLDatabaseToolkit(db=db, llm=llm)

all_tools = toolkit.get_tools() + [
    Tool(
        name="sql_db_query",
        func=safe_sql_query,
        description="Run SQL queries safely against the database."
    ),
    Tool(
        name="churn_predictor",
        func=churn_predictor_tool,
        description="Identify customers likely to churn. No input required."
    ),
    Tool(
        name="simulate_ltv",
        func=simulate_ltv_tool,
        description="Project future lifetime value for a customer using subscription + referrals + inactivity."
    ),
    Tool(
        name="simulate_affinity",
        func=simulate_product_affinity_tool,
        description="Predict next likely product category for a customer (e.g., serum → skincare)."
    )
]

# --------------------------------------------------------------------------------
# Step 5: Prompt
# --------------------------------------------------------------------------------
SQL_PROMPT = PromptTemplate(
    input_variables=["input", "agent_scratchpad", "table_info", "dialect", "top_k", "tools", "tool_names"],
    template="""
You are an expert SQL + analytics agent.

RULES:
- Always return results in 3 sections:
  1) User List — numbered, with key fields.
  2) Summary — count, patterns, insight.
  3) Explanation — which business rule/tool was used.

- Do NOT include markdown fences (```sql).
- If query is about churn → use churn_predictor.
- If query is about next purchase → use simulate_affinity.
- If query is about lifetime value → use simulate_ltv.
- Otherwise → use sql_db_query.

FEW-SHOT HINTS
Example 1 — Predictive churn risk:
User Query: "Which customers are likely to churn soon?"
Thought: This is a predictive query about churn risk. I must call the `churn_predictor` tool.
Action: churn_predictor
Action Input: {}
Observation:
1) Sophia Smith — CustomerID: CUST11001, Email: sophia.smith1@example.com, Phone: 8012140042, Churn Risk: True
2) Emma Williams — CustomerID: CUST11002, Email: emma.williams1@example.com, Phone: 7886811197, Churn Risk: True
Final Answer:
1) Sophia Smith — ...
2) Emma Williams — ...
Summary: Found 2 customers with high churn risk.
Explanation: Prediction simulated using business rules.

Example 2 — Inactive customers:
User Query: "Show customers who haven’t purchased in a long time."
Thought: "Inactive" = last purchase > 25 days ago.
Action: sql_db_query
Action Input: SELECT customerid, name, email_id, phone_number,
                     julianday('now') - julianday(last_transaction_date) AS days_since_last_transaction
              FROM users
              WHERE julianday('now') - julianday(last_transaction_date) > 25;
Observation: [...]
Final Answer: ...
Summary: ...
Explanation: "Inactive" interpreted as last purchase > 25 days.

Example 3 — High-value customers:
User Query: "List high-value customers in Bangalore"
Thought: High-value = top 10% spenders, plus location = Bangalore.
Action: sql_db_query
Action Input: SELECT ...
Observation: [...]
Final Answer: ...
Summary: ...
Explanation: Applied high-value + Bangalore filters.

Example 4 — Product synonyms:
User Query: "List users who bought serum"
Thought: Map serum → skincare using category_lexicon.
Action: sql_db_query
Action Input: SELECT ...
Observation: [...]
Final Answer: ...
Summary: ...
Explanation: Serum mapped to skincare.

User Question: {input}
{agent_scratchpad}
"""
)

# --------------------------------------------------------------------------------
# Step 6: Agent
# --------------------------------------------------------------------------------
agent_executor = initialize_agent(
    tools=all_tools,
    llm=llm,
    agent="zero-shot-react-description",
    verbose=True,
    handle_parsing_errors=True,
    prompt=SQL_PROMPT,
)

print("--- SQL Agent ready ---")

response = agent_executor.invoke("List customers who are likely to churn soon")
print(f"List customers who are likely to churn soon':\n{response['output']}")

response = agent_executor.invoke("Predict future LTV for customers in Mumbai with active subscriptions")

response = agent_executor.invoke("High-value active customers in Mumbai")
print(f"\nHigh-value inactive customers in Mumbai':\n{response['output']}")

response = agent_executor.invoke("Show me customers who haven’t purchased in a long time.")

response = agent_executor.invoke("Show loyal customers with active subscriptions.")

response = agent_executor.invoke("List 5 users with the highest referral_earning.")
print(f"\nResponse to 'List 5 users with the highest referral_earning.':\n{response['output']}")

response = agent_executor.invoke("Show customers who spent more than 50000 but raised more than 3 support tickets.")

response = agent_executor.invoke("Which customers live in Bangalore and use Credit Card subscription?")
print(f"\nResponse to 'Which customers live in Bangalore and use Credit Card subscription?':\n{response['output']}")

response = agent_executor.invoke("List top 5 users who made the highest transaction in skincare category.")
print(f"\nResponse to 'List top 5 users who made the highest transaction in skincare category.':\n{response['output']}")

response = agent_executor.invoke("List top 5 users who are most likely to buy a serum.")
print(f"\nResponse to 'List top 5 usersost likely to buy a serum':\n{response['output']}")

response = agent_executor.invoke("Find all customers who recently bought electronic products")
print(f"\nResponse to 'Customers who recently bought electronic products':\n{response['output']}")

!pip install fastapi uvicorn pyngrok nest_asyncio

# Commented out IPython magic to ensure Python compatibility.
# %%writefile index.html
# 
# <!DOCTYPE html>
# <html lang="en">
# <head>
#     <meta charset="UTF-8">
#     <meta name="viewport" content="width=device-width, initial-scale=1.0">
#     <title>Customer Targeting Agent 🎯</title>
#     <style>
#         @import url('https://fonts.googleapis.com/css2?family=Poppins:wght@400;600&display=swap');
#         body {
#             font-family: 'Poppins', sans-serif;
#             background-color: #e6f0ff; /* Light blue background */
#             color: #2c3e50; /* Dark gray text */
#             display: flex;
#             justify-content: center;
#             align-items: center;
#             min-height: 100vh;
#             margin: 0;
#             padding: 20px;
#         }
#         .container {
#             width: 90%;
#             max-width: 900px;
#             background-color: #ffffff; /* White card */
#             padding: 40px;
#             border-radius: 16px;
#             box-shadow: 0 8px 30px rgba(0, 0, 0, 0.1);
#             text-align: center;
#         }
#         h2 {
#             font-weight: 600;
#             color: #1e3a8a; /* Dark blue heading */
#             margin-bottom: 20px;
#             font-size: 28px;
#             display: flex;
#             align-items: center;
#             justify-content: center;
#         }
#         h2 .emoji {
#             font-size: 32px;
#             margin-right: 10px;
#         }
#         .input-group {
#             display: flex;
#             align-items: center;
#             margin-top: 20px;
#         }
#         #query {
#             flex-grow: 1;
#             padding: 14px 20px;
#             font-size: 16px;
#             border: 2px solid #b3d3ff; /* Light blue border */
#             border-radius: 12px;
#             transition: border-color 0.3s, box-shadow 0.3s;
#         }
#         #query:focus {
#             outline: none;
#             border-color: #3b82f6; /* Focus blue */
#             box-shadow: 0 0 0 4px rgba(59, 130, 246, 0.2);
#         }
#         button {
#             padding: 14px 28px;
#             font-size: 16px;
#             font-weight: 600;
#             background-color: #3b82f6; /* Main button color */
#             color: white;
#             border: none;
#             border-radius: 12px;
#             cursor: pointer;
#             transition: background-color 0.3s, transform 0.2s;
#             margin-left: 15px;
#         }
#         button:hover {
#             background-color: #2563eb;
#             transform: translateY(-2px);
#         }
#         #response-container {
#             margin-top: 30px;
#             background-color: #f8faff; /* Lighter background for results */
#             border-radius: 12px;
#             padding: 20px;
#             text-align: left;
#             min-height: 120px;
#             box-shadow: inset 0 2px 4px rgba(0, 0, 0, 0.05);
#             overflow-x: auto;
#         }
#         #response-container.loading {
#             display: flex;
#             justify-content: center;
#             align-items: center;
#         }
#         .spinner {
#             border: 4px solid rgba(0, 0, 0, 0.1);
#             border-left-color: #3b82f6;
#             border-radius: 50%;
#             width: 30px;
#             height: 30px;
#             animation: spin 1s linear infinite;
#         }
#         @keyframes spin {
#             to { transform: rotate(360deg); }
#         }
#         #response-text {
#             font-family: monospace;
#             white-space: pre-wrap;
#             word-wrap: break-word;
#             font-size: 14px;
#             color: #1f2937;
#         }
#         /* Style for the table output */
#         #response-text table {
#             width: 100%;
#             border-collapse: collapse;
#             font-size: 14px;
#             background-color: #ffffff;
#             border: 1px solid #e5e7eb;
#             border-radius: 8px;
#         }
#         #response-text th, #response-text td {
#             border: 1px solid #e5e7eb;
#             padding: 12px;
#             text-align: left;
#         }
#         #response-text th {
#             background-color: #f3f4f6;
#             color: #4b5563;
#         }
#         #response-text tr:nth-child(even) {
#             background-color: #f9fafb;
#         }
#     </style>
# </head>
# <body>
#     <div class="container">
#         <h2><span class="emoji">🕵️‍♀️</span> AI-Powered Customer Targeting Agent</h2>
#         <div class="input-group">
#             <input type="text" id="query" placeholder="e.g., Show me high-spending customers for a new skincare product">
#             <button onclick="askAgent()">Submit</button>
#         </div>
#         <div id="response-container">
#             <pre id="response-text">Your results will appear here...</pre>
#         </div>
#     </div>
# 
#     <script>
#         async function askAgent() {
#             const query = document.getElementById("query").value;
#             const responseContainer = document.getElementById("response-container");
#             const responseText = document.getElementById("response-text");
# 
#             if (!query) {
#                 responseText.textContent = "Please enter a query.";
#                 return;
#             }
# 
#             // Show loading state
#             responseContainer.classList.add("loading");
#             responseText.innerHTML = '<div class="spinner"></div>';
# 
#             try {
#                 const res = await fetch("/query_agent", {
#                     method: "POST",
#                     headers: { "Content-Type": "application/json" },
#                     body: JSON.stringify({ query: query })
#                 });
# 
#                 const data = await res.json();
#                 if (data.error) {
#                     responseText.textContent = 'Error: ' + data.error;
#                     responseContainer.style.backgroundColor = '#fecaca';
#                 } else {
#                     responseText.textContent = "";
#                     responseText.innerHTML = data.response;
#                     responseContainer.style.backgroundColor = '#d1fae5';
#                 }
#             } catch (error) {
#                 responseText.textContent = 'Failed to connect to the agent. Please check the server.';
#                 responseContainer.style.backgroundColor = '#fecaca';
#             } finally {
#                 responseContainer.classList.remove("loading");
#             }
#         }
#     </script>
# </body>
# </html>
#

from fastapi import FastAPI, HTTPException
from fastapi.responses import FileResponse
from pydantic import BaseModel
import uvicorn, nest_asyncio, threading
from pyngrok import ngrok


# ---- FastAPI setup ----
app = FastAPI()

class QueryRequest(BaseModel):
    query: str

@app.post("/query_agent")
async def query_agent(request: QueryRequest):
    try:
        response = agent_executor.invoke({"input": request.query})
        return {"response": response.get("output", "NO ANSWER")}
    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))

# Serve UI
@app.get("/")
def serve_ui():
    return FileResponse("index.html")

# ---- Ngrok tunnel ----
NGROK_AUTH_TOKEN = "30uTE3Xo0Ipqaf8Her8zTQ7di9z_3THeVcRbswxDoK1Ly4bT8"
ngrok.set_auth_token(NGROK_AUTH_TOKEN)
from pyngrok import ngrok
ngrok.kill()


public_url = ngrok.connect(5000)
print("Public URL:", public_url.public_url)

# ---- Run FastAPI server in background ----
nest_asyncio.apply()
def run_app():
    uvicorn.run(app, host="0.0.0.0", port=5000)

threading.Thread(target=run_app, daemon=True).start()